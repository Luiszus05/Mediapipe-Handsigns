{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Mediapipe handsign recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time as t\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\Luis\\OneDrive\\Desktop\\Maturaarbeit\\codingMA\\Mediapipe\\models\"\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = [\"right\", \"left\", \"up\", \"down\", \"fist\", \"hand\", \"V\"]\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "def test(frame):\n",
    "    results = hands.process(frame)\n",
    "        \n",
    "    if results.multi_hand_landmarks: \n",
    "        points = []\n",
    "        for handLandmarks in results.multi_hand_landmarks:\n",
    "            for landmark in handLandmarks.landmark:\n",
    "                x, y, z = landmark.x, landmark.y, landmark.z\n",
    "                points.append(x)\n",
    "                points.append(y)\n",
    "                points.append(z)\n",
    "            drawingModule.draw_landmarks(frame, handLandmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "        return np.array(points)\n",
    "       \n",
    "    else: \n",
    "        return np.array([0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"preview\")\n",
    "\n",
    "while True:\n",
    "    rval, frame = vc.read()\n",
    "    res = test(frame)\n",
    "    if sum(res) != 0:\n",
    "        res = np.reshape(res, (1, res.shape[0]))\n",
    "        res = model(res)\n",
    "        cv2.putText(frame, signs[np.argmax(res)] ,(250,80), 4,2, (0,0,0),2)\n",
    "        cv2.imshow('preview', frame)\n",
    "        cv2.waitKey(100)\n",
    " \n",
    "    elif cv2.waitKey(100) & 0xFF == ord(\" \"): \n",
    "        break\n",
    "\n",
    "    else:\n",
    "        cv2.imshow(\"preview\", frame)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "del(vc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
